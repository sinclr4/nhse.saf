[{"id":0,"href":"/docs/nhs-england-architecture-framework/","title":"NHS England Solution Architecture Framework","section":"Docs","content":" Introduction # The NHS England Solution Architecture Framework (SAF) is intended to describe what good looks like when developing the architecture which delivers our products and services by defining:\nA consistent approach to the design of solutions which delivers on user need, but also considers other key factors such as cyber security, service resilience, performance etc. The artefacts Solution Architects should be producing The processes and governance that should be implemented As well as describing what areas are important it also provides a baseline to assess the architectural fitness of our products and services. Alongside the assessment it provides a focus for risk mitigation.\nFull compliance is not expected, and a pragmatic approach needs to be taken which considers risk alongside other factors such as service criticality, user, patient impacts, architecture priority score, data classification etc.\nUltimately the architecture approaches and choices we make are not binary decisions and involve trade offs. The SaF has to deal with a higher level of subjectivity than perhaps other models such as the engineering redlines where elements can be mandated.\nThe architect and supporting product team will need to make judgement calls, based on specific circumstances and team experience. The SaF is not intended to cover every eventuality or provide explicit direction for every point. In terms of assessment we should focus on broad patterns and trends rather empirical comparisons of scores e.g. look for quality improvements around red and amber areas but don’t compare scores between products or rank based on score.\nThe SAF is expected to be used alongside the NHS England Software Engineering Quality Framework. There are natural overlaps between these two frameworks and the engineering redlines. (Red lines (sharepoint.com)). We think there will be great value in being able to articulate quality across the engineering and architecture perspectives to identify risks \u0026amp; issues in our priority services.\nIt’s worth noting that whilst there are some areas of overlap between the Engineering redlines, the SAF has a broader applicability e.g. outside of P\u0026amp;P led delivery, buy options and earlier engagement prior to any build activity. There are also some overlaps with AWS and Azure Well Architected Frameworks. These frameworks should be used alongside the NHS SAF and will provide an evidence base for overall assessments.\nWhere there are overlaps particularly with early engagement, we need to ensure assessments are kept consistent and not repeated unnecessarily or unknowingly.\nIt be noted that additional material will be required to support the SAF e.g. creation of policy, patterns and best practice guidance to support decision making. The SAF will provide the “headings” for the supporting collateral, for example:-\n![A diagram of a solution\nWe expect this document to be used alongside existing prescribed methodologies and standards such as CDDO checklists, Service Design Manual and other spend control related collateral.\nCore Dimensions of the SAF # The SAF is broken down into seven dimensions, each with a set of architectural requirements which will describe what elements need to be in place and to allow a subsequent appraisal of those elements and their appropriateness.\nStrategic Alignment, Vision, and Roadmap Describes how well the solution architecture aligns with our strategic direction, our policies, and principles. Re Use Principles and Development of Shared Services Are we building re-useable components, are we reusing what we have already in an effective manner? Documentation Are we documenting the architectures to an appropriate level of detail, are we following our standards around Enterprise Architecture tooling. Is documentation open and shared? Decision Making \u0026amp; Governance Are we following governance processes, managing risk and issues, communicating with our stakeholders? Are we managing technical debt? Do we have a framework in place to make decisions which is based are based on understanding need, options analysis, clear rationale, and management of trade-offs? Are we communicating those decisions? Technology Choices Are we making the right technology choices in line with our technology radar and other strategic choices? https://radar.engineering.england.nhs.uk/ Non-Functional Design Do we understand the non-functional needs of the service, are we creating a solution which can meet those need and be flexible, without over engineering? Solution Design \u0026amp; Methods Are we following recognised industry best practice in our designs e.g. separation of concerns? Are we giving sufficient focus to ensure interoperability / integration is built into our designs from day 1, using the right patterns and standards? How Will the NHS England SaF be used # Day to Day Usage # As part of the BAU activities of Solution Architects working within delivery teams we will expect them to use the SAF to help structure their activities, their approach to solutions design, documentation and decision making. The SAF will act as an “aide memoir” for Solution Architects to drive a consistent approach, regardless of whether they are permanent, contract or supplier colleague.\nThe SAF isn’t a set of hard and fast rules but is intended to guide architects and product teams make the right decisions, drive up quality and to be able to provide rationale for the trade offs we ultimately have to make.\nFurther information and guidance will be developed on the specifics of the framework e.g. best practice document templates, non-functional requirement sets, good practice governance. We will expect and positively encourage Solution Architects to actively contribute back into the framework and wider community of practice by developing supporting collateral.\nArchitecture Fitness Assessment # Alongside day to day use we will require architects to perform periodic reviews of existing products plus those in development\nSolution Architects will be required to undertake a review of maturity/compliance against the requirements for each of the key products within their portfolios. Any review should not be done in isolation and should be done with the product owner and wider product team The review must be positioned as a helpful tool to highlight risks, issues and areas for improvement The outcome of the assessments will be an architecture remediation plan. Depending on the risks the remediation plan may be managed by the product team themselves as part of BAU or for high-risk assessments will be tracked by the appropriate governance group. This needs to be agreed collectively by the product team. Architecture assessment should be presented alongside wider dimensions including software quality framework and the engineering redlines. We should not rank or compare products based on their SAF assessment i.e. a 55 in one product for a SaF dimension does not translate to higher quality, less risk etc than a product which scores 61. Judgement should be applied based on the product and the associated risk (and lifecycle stage) . Overall Guidance # The assessment mechanism described below is intended to be risk based and several factors should be considered whilst undertaking a review:\nConsider the service level and business criticality i.e. simple noncritical applications which may be poorly designed or have poor architecture processes may present a low impact of failure to users and therefore remediation actions should be considered appropriately. Measuring adherence to the requirement is not binary and will have an unavoidable level of subjectivity. A product may achieve one requirement well in some places and not in others. Exercise cautious pragmatism and team judgement when undertaking a review. When doing reviews consider the solution, but also as a set of individual components. For example, the overall solution may be considered well architected however a single critical component maybe very weak and therefore present significant risk to the overall solution Ensure the right people are involved in the review Don’t see the assessment as a one off exercise or a gate review – it should be a continuous process, particularly for new and emerging products Use the continuous review process to inform product backlogs and team ways of working, building into standard ceremonies e.g. sprint planning and retros Requirements \u0026amp; Outcomes # For each requirement statement the architect needs to assess how well the architecture and supporting processes meet the objective of the requirement and the overall dimension of the SAF.\nThere may be different ways a requirement can be met. We should focus on the outcome and satisfy ourselves that the evidence provided can meet it.\nThe assessment can be made via interviews, document reviews, cloud provider Well Architected Framework reviews[1], delivery team meetings and ceremonies etc. It is not a one size fits all and will vary depending on the team make up etc. At all times we be risk based.\nAn assessment spreadsheet has been created which allows for a score based on the criteria below. Each requirement is some form of weighting to ensure more significant or complex requirements are accounted for. (Note. The weighting will be subject to change and review.)\nScore Compliance Criteria 0 No evidence that the requirement is supported and as such presents significant service risk. 1 Limited evidence that the requirement is supported with high risks gaps. 2 Some elements of the requirement are met with an acceptable level of evidence, but significant number of notable gaps. 3 Much of the requirement is met with an acceptable level of evidence, but there are notable gaps which present risk which require mitigating action. 4 Most of the requirement is met with good levels of evidence, there are some gaps but are not thought to present significant risk. 5 Comprehensive evidence that the requirements is met and exceeds expectations in several areas. We would consider this an exemplar. This is not an exact science and in many cases it will be challenging to judge particularly where underpinning material such as strategies, principles, polices etc are not in place. Within the requirements spreadsheet there will be some guidance to help give a sense for example\n5 = A strategy paper has been produced, openly published, well socialised, approved at executive level and is widely accepted and baked into governance 3 = Some form of strategy has been written down and generally seems well accepted at a directorate level, but may not be openly published. Teams outside of a directorate might not consistently recognise it as a formal strategy 1 = Nothing recognisable as a strategy, written down or otherwise Based on the assessment the architect and product team should agree a remediation plan for those areas considered more significant e.g. where one of the dimensions has a “AMBER” or “RED” score OR where there is one specific area the team are concerned about. Whilst the RAG rating is more important than the specific scores care should be taken that significant issues \u0026amp; risks are not lost as scores get weighted and averaged out\nRemediation planning should be tracked via an appropriate mechanism depending on the risk \u0026amp; issues identified. For instance live services which have significant amber and red ratings might be tracked at an executive level such as the Design Authority, less significant via TRG or within the delivery team as part of BAU processes.\nWe need to be able to reflect the health of our solution architectures in a simple and digestible form. The example below demonstrates a simple dashboard view for each product, this view will be enhanced as we undertake the initial review exercises and gather stakeholder feedback.\nWe will be making use of the EA tooling capability to capture this data and make available via automated dashboards etc.\nFramework Requirements # Strategic Alignment, Vision, and roadmap # Requirements S01 The solution should be aligned to stated strategy approved at an executive level e.g. TD Design Authority, P\u0026amp;P DA etc. S02 We should be able to demonstrate which capabilities from the NHSE Business Capability Model the solution is realising, and any potential duplication identified S03 A well-formed and maintained product vision \u0026amp; roadmap should exist with appropriate detail around architecture elements S04 The solution design should be able to meet the stated user needs and overall business objectives/drivers Decision Making \u0026amp; Governance # Requirements DM01 Where a solution or part of solution is seen as tactical, short term or introduces / persist tech \u0026amp; architecture debt, remediations plans should be in place and agreed with the relevant stakeholders and governance groups.Architecture Debt should be identified with implications, rationale and future mitigations plans (recorded in a Architecture Debt Register)Plans should be realistic and funded. DM02 Spend control (GATS) and associated Government Digital Services \u0026amp; Service Design related guidance should be followed whilst developing the solution and be evidenced for service design \u0026amp; spend control reviews DM03 Architecture risks and issues should be managed effectively with the appropriate level of visibility and ownership DM04 There should be effective and commensurate stakeholder involvement with respects to solution design and architecture decisions. DM05 The solution design and architecture decisions should be managed effectively through local programme design authorities and TRG at the appropriate stages of the lifecycle.The relevant Lead Architects and SMEs are engaged and are supportive DM06 The overall approach to architecture governance should be appropriate and commensurate with the nature of the solution DM07 All Architecture decisions should be documented with a lightweight Architecture Decision Record with options and clear rationale.E.g. software-engineering-quality-framework/any-decision-record-template.md at main · NHSDigital/software-engineering-quality-framework · GitHub DM08 All decision-making should be structured i.e. identify key strategic drivers, user need assess options against drivers, present rationale, clarity on trade-offs, dependencies, risks and issues understood etc. Solution Design \u0026amp; Methods # Technology Choices # Requirements T1 Technology choices should be made in line with the NHS England Technology Radar, corporate direction and wider industry trends using the associated processes to support decision making . Tech Radar(Note there are overlaps with the Engineering red lines, ensure a consistent response and do not repeat assessments) T2 Technology choices should be appropriate to the problem and non-functional needs i.e. we are as equally aware of over engineering as we are to under engineering. T3 An appraisal should be made of any vendor lock considerations and associated risks, and these are understood and accepted/mitigated. Non-Functional Profile # Requirement NF1 Solutions should incorporate workload observability and understand service health NF2 Reliability \u0026amp; Resilience needs should be defined (in terms of standard NHS England service levels) and solution mechanisms to meet these needs are defined including metrics such as RTO, RPO etc. NF3 An overall volume and performance model should exist and includes business-realistic exceptional scenarios. NF4 Methods to measure sustainability to establish baseline and show improvement should be defined. NF5 Audit \u0026amp; logging requirements should be defined, and the solution can support themhttps://www.ncsc.gov.uk/collection/device-security-guidance/managing-deployed-devices/logging-and-protective-monitoringhttps://www.ncsc.gov.uk/collection/cloud/the-cloud-security-principles/principle-13-audit-information-and-alerting-for-customers NF6 Disaster Recovery \u0026amp; Business ContinuityThere should be clear requirements (commensurate with service levels) around DR \u0026amp; BC (and a pragmatic approach taken with regards DR/BC events planned for)Continuity plans and supporting documentation should reflect the requirements, technical \u0026amp; architecture constraints etc. Re Use Principles and Development of Shared Services # Requirements RU1 If reusing existing capabilities, we should have confidence that any additional functionality required can be sensibly and cost effectively added to the existing service i.e we are not bending something out of shape RU2 For new capabilities we should identify/recognise the potential re use opportunities which may drive design decisions, benefits etc. RU3 We should reuse capabilities as defined below:- Capability Re Use Cohorting CaaS Citizen Messaging NHS Notify Staff Messaging GOV.Notify and nhs.connect Application Messaging MESH or alternative as required Demographics/MPI PDS Eventing MNS API Management NHSE API Management Platform (which uses Apigee underneath) Identity CIS2 Auth/NHS Mail SSO/NHS login Logging \u0026amp; Monitoring Splunk/Sentinel/Cribl/Grafana (tbc – pending ODIN) Data Analytics FDP/CDP/DPS - FDP First Public facing web presence NHS.uk Patient Flags Flags service Organisational Data ODS | Shared Services | | | \u0026mdash; | | \u0026mdash; | | Capability | Re Use | | Auditing | Standard Audit tools/PARS (when live) | | Cyber Security Monitoring | CSOC | | Service Management \u0026amp; Support | ServiceNow |\nDocumentation # The review process - AWS Well-Architected Framework (amazon.com) ↑ "}]